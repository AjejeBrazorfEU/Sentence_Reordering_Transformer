{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElNaMbLnRdHR"
      },
      "source": [
        "Luca Domeniconi luca.domeniconi5@studio.unibo.it (student-id: 0001113308)\n",
        "\n",
        "-------\n",
        "\n",
        "# Sentence Reconstruction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXr4iGUGRms8"
      },
      "source": [
        "The purpose of this project is to take in input a sequence of words corresponding to a random permutation of a given english sentence, and reconstruct the original sentence.\n",
        "\n",
        "The otuput can be either produced in a single shot, or through an iterative (autoregressive) loop generating a single token at a time.\n",
        "\n",
        "\n",
        "CONSTRAINTS:\n",
        "* No pretrained model can be used.\n",
        "* The neural network models should have less the 20M parameters.\n",
        "* No postprocessing should be done (e.g. no beamsearch)\n",
        "* You cannot use additional training data.\n",
        "\n",
        "\n",
        "BONUS PARAMETERS:\n",
        "\n",
        "A bonus of 0-2 points will be attributed to incentivate the adoption of models with a low number of parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ8k-L-WUK7l"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "The dataset is composed by sentences taken from the generics_kb dataset of hugging face. We restricted the vocabolary to the 10K most frequent words, and only took sentences making use of this vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nJ02vehGYySk",
        "outputId": "e40e988a-dab7-4d6f-f44c-678273e9dba9"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "807Wk-ir_bDU"
      },
      "source": [
        "Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WjtqA8TrHcS",
        "outputId": "236c477f-7981-454e-cfd1-a19118566134"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Luca\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from keras.layers import TextVectorization\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "SEED = 24\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyYpXLCF_ldR"
      },
      "source": [
        "Create a tokenizer and Detokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "T-bE2JpVbU9E"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading tokenizer and original data.\n",
            "WARNING:tensorflow:From c:\\Users\\Luca\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class TextDetokenizer:\n",
        "        def __init__(self, vectorize_layer):\n",
        "                self.vectorize_layer = vectorize_layer\n",
        "                vocab = self.vectorize_layer.get_vocabulary()\n",
        "                self.index_to_word = {index: word for index, word in enumerate(vocab)}\n",
        "\n",
        "        def __detokenize_tokens(self, tokens):\n",
        "                def check_token(t):\n",
        "                    if t == 3:\n",
        "                        s=\"<start>\"\n",
        "                    elif t ==2:\n",
        "                        s=\"<end>\"\n",
        "                    elif t ==7:\n",
        "                        s=\"<comma>\"\n",
        "                    else:\n",
        "                        s=self.index_to_word.get(t, '[UNK]')\n",
        "                    return s\n",
        "\n",
        "                return ' '.join([ check_token(token) for token in tokens if token != 0])\n",
        "\n",
        "        def __call__(self, batch_tokens):\n",
        "             return [self.__detokenize_tokens(tokens) for tokens in batch_tokens]\n",
        "\n",
        "# check if the tokenizer is already saved\n",
        "try:\n",
        "    print(\"Loading tokenizer and original data.\")\n",
        "    # Load the tokenizer with pickle\n",
        "    with open('tokenizer.pkl', 'rb') as f:\n",
        "        tokenizer_data = pickle.load(f)\n",
        "        tokenizer = TextVectorization.from_config(tokenizer_data[\"config\"])\n",
        "        tokenizer.set_weights(tokenizer_data[\"weights\"])\n",
        "        detokenizer = TextDetokenizer( tokenizer )\n",
        "    \n",
        "    # Read original_data with pickle\n",
        "    with open('original_data.pkl', 'rb') as f:\n",
        "        original_data = pickle.load(f)\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    print(\"Tokenizer or original data not found. Creating new ones.\")\n",
        "    # Create a new tokenizer\n",
        "    ds = load_dataset('generics_kb',trust_remote_code=True)['train']\n",
        "    ds = ds.filter(lambda row: len(row['generic_sentence'].split(\" \"))>8 )\n",
        "    corpus = [ '<start> ' + row['generic_sentence'].replace(\",\",\" <comma>\") + ' <end>' for row in ds ]\n",
        "    corpus = np.array(corpus)\n",
        "    tokenizer=TextVectorization( max_tokens=10000, standardize=\"lower_and_strip_punctuation\")\n",
        "    tokenizer.adapt(corpus)\n",
        " \n",
        " \n",
        "    detokenizer = TextDetokenizer( tokenizer )\n",
        "    sentences = tokenizer( corpus ).numpy()\n",
        " \n",
        "    mask = np.sum( (sentences==1) , axis=1) >= 1\n",
        "    original_data = np.delete( sentences, mask , axis=0)\n",
        "    original_data = [sen for sen in tokenizer(corpus).numpy() if not(1 in sen) and len(sen)>4 and len(sen)<= 32]\n",
        " \n",
        "# Shuffle the original_data\n",
        "shuffled_indices = np.random.permutation(len(original_data))\n",
        "original_data = np.array(original_data)[shuffled_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the DataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1ZXLkWB6od0R"
      },
      "outputs": [],
      "source": [
        "from keras.utils import Sequence\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "        def __init__(self, data, batch_size=32, shuffle=True, seed=None):\n",
        "\n",
        "            self.data = data\n",
        "            self.batch_size = batch_size\n",
        "            self.shuffle = shuffle\n",
        "            self.seed = seed\n",
        "            self.on_epoch_end()\n",
        "\n",
        "        def __len__(self):\n",
        "            return int(np.floor(len(self.data) / self.batch_size))\n",
        "\n",
        "        def __getitem__(self, index):\n",
        "            indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "            data_batch = np.array([self.data[k] for k in indexes])\n",
        "            #cop of ordered sequences\n",
        "            result = np.copy(data_batch)\n",
        "            #shuffle only the relevant positions for each batch\n",
        "            for i in range(data_batch.shape[0]):\n",
        "                np.random.shuffle(data_batch[i,1:data_batch[i].argmin() - 1])\n",
        "\n",
        "            return data_batch , result\n",
        "\n",
        "        def on_epoch_end(self):\n",
        "            self.indexes = np.arange(len(self.data))\n",
        "            if self.shuffle:\n",
        "                if self.seed is not None:\n",
        "                    np.random.seed(self.seed)\n",
        "                np.random.shuffle(self.indexes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo8MazCGBTv3"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0NOkuO0CfPo"
      },
      "source": [
        "Let s be the source string and p your prediction. The quality of the results will be measured according to the following metric:\n",
        "\n",
        "1.  look for the longest substring w between s and p\n",
        "2.  compute |w|/max(|s|,|p|)\n",
        "\n",
        "If the match is exact, the score is 1.\n",
        "\n",
        "When computing the score, you should NOT consider the start and end tokens.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-aUrdlXDdVf"
      },
      "source": [
        "The longest common substring can be computed with the SequenceMatcher function of difflib, that allows a simple definition of our metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ulpTRdrF_huh"
      },
      "outputs": [],
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "def score(s,p):\n",
        "    match = SequenceMatcher(None, s, p).find_longest_match()\n",
        "    return (match.size/max(len(p),len(s)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB2YfjXNExM-"
      },
      "source": [
        "Let's do an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "h17C8bVjEwur"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "your score is  0.5423728813559322\n"
          ]
        }
      ],
      "source": [
        "original = \"at first henry wanted to be friends with the king of france\"\n",
        "generated = \"henry wanted to be friends with king of france at the first\"\n",
        "\n",
        "print(\"your score is \",score(original,generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5\n"
          ]
        }
      ],
      "source": [
        "print(score(\"2 1 20 3 0 0\", \"2 20 1 3 0 0\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BET8GqBvFugR"
      },
      "source": [
        "The score must be computed as an average of at least 3K random examples taken form the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fwo7xj4GBW1"
      },
      "source": [
        "# What to deliver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6uITuxOGHfJ"
      },
      "source": [
        "You are supposed to deliver a single notebook, suitably commented.\n",
        "The notebook should describe a single model, although you may briefly discuss additional attempts you did.\n",
        "\n",
        "The notebook should contain a full trace of the training.\n",
        "Weights should be made available on request.\n",
        "\n",
        "You must also give a clear assesment of the performance of the model, computed with the metric that has been given to you.\n",
        "\n",
        "# Good work!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this project I implemented a Transformer model based on the [Tensorflow implementation](https://www.tensorflow.org/text/tutorials/transformer), that follows the original paper [\"Attention Is All You Need\"](https://arxiv.org/pdf/1706.03762).\n",
        "\n",
        "The transformer takes as input two values:\n",
        "1) `Context`: contains the scrambled phrase, it is fed into the input of the Encoder and has a shape of (`batch_size`, `max_len`) \n",
        "2) `x`: contains the input of the Decoder and has a shape of (`batch_size`, `max_len`).\n",
        "\n",
        "The transformer output has the following shape:\n",
        "\n",
        "(`batch_size`, `max_len`, `max_len`)\n",
        "\n",
        "and contains for each position the probability of the next token to be the $i$-th token in the `Context`. Basically, instead of outputting a probability for each word in the dictionary, it outputs the probability for each token in the `Context` to be the next token in the prediction. In this way, the model can only output words from the `Context` and not words from the entire dictionary, making it easier to train.\n",
        "\n",
        "\n",
        "During the training phase, `x` contains the ground truth (ordered phrase). During the inference phase, `x` contains initially only the `<start>` token, and each call to the model generates a new token that gets appended."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import MultiHeadAttention, LayerNormalization, Add, Embedding, Dense, Dropout, Layer\n",
        "from keras import Sequential, Model\n",
        "import numpy as np\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from keras.optimizers import Adam, AdamW\n",
        "\n",
        "class BaseAttention(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "        self.mha = MultiHeadAttention(**kwargs)\n",
        "        self.layernorm = LayerNormalization()\n",
        "        self.add = Add()\n",
        "        \n",
        "class CrossAttention(BaseAttention):\n",
        "    def call(self, x, context):\n",
        "        x = tf.cast(x, tf.float64)\n",
        "        context = tf.cast(context, tf.float64)\n",
        "        attn_output, attn_scores = self.mha(\n",
        "                query=x,\n",
        "                key=context,\n",
        "                value=context,\n",
        "                return_attention_scores=True)\n",
        "\n",
        "        x = self.add([x, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class GlobalSelfAttention(Layer):\n",
        "    def __init__(self, num_heads, key_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, dropout=dropout)\n",
        "        self.layernorm = LayerNormalization()\n",
        "        self.add = Add()\n",
        "        \n",
        "    def call(self, x):\n",
        "        x = tf.cast(x, tf.float64)\n",
        "        attn_output = self.mha(\n",
        "                query=x,\n",
        "                value=x,\n",
        "                key=x)\n",
        "        x = self.add([x, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "        return x\n",
        "\n",
        "class CausalSelfAttention(BaseAttention):\n",
        "    def call(self, x):\n",
        "        x = tf.cast(x, tf.float64)\n",
        "        attn_output = self.mha(\n",
        "                query=x,\n",
        "                value=x,\n",
        "                key=x,\n",
        "                use_causal_mask = True)\n",
        "        x = self.add([x, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "        return x\n",
        "\n",
        "def positional_encoding(length, depth):\n",
        "    depth = depth/2\n",
        "\n",
        "    positions = np.arange(length)[:, np.newaxis]         # (seq, 1)\n",
        "    depths = np.arange(depth)[np.newaxis, :]/depth     # (1, depth)\n",
        "\n",
        "    angle_rates = 1 / (10000**depths)                 # (1, depth)\n",
        "    angle_rads = positions * angle_rates            # (pos, depth)\n",
        "\n",
        "    pos_encoding = np.concatenate(\n",
        "            [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "            axis=-1) \n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "class PositionalEmbedding(Layer):\n",
        "    def __init__(self, vocab_size, d_model, max_len):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = Embedding(vocab_size, d_model, mask_zero=True) \n",
        "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def compute_mask(self, *args, **kwargs):\n",
        "        return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "    def call(self, x):\n",
        "        length = self.max_len\n",
        "        # length = x.shape[1]\n",
        "        x = self.embedding(x)\n",
        "        # This factor sets the relative scale of the embedding and positonal_encoding.\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        pos_encoding = positional_encoding(length, self.d_model)\n",
        "        x = x + pos_encoding[tf.newaxis, :length, :]\n",
        "\n",
        "        return x\n",
        "\n",
        "class FeedForward(Layer):\n",
        "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.seq = Sequential([\n",
        "            Dense(dff, activation='swish'),\n",
        "            Dense(d_model),\n",
        "            Dropout(dropout_rate)\n",
        "        ])\n",
        "        self.add = Add()\n",
        "        self.layer_norm = LayerNormalization()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.add([x, self.seq(x)])\n",
        "        x = self.layer_norm(x) \n",
        "        return x\n",
        "\n",
        "class EncoderLayer(Layer):\n",
        "    def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attention = GlobalSelfAttention(\n",
        "                num_heads=num_heads,\n",
        "                key_dim=d_model,\n",
        "                dropout=dropout_rate)\n",
        "\n",
        "        self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.self_attention(x)        \n",
        "        x = self.ffn(x)\n",
        "        return x\n",
        "    \n",
        "class Encoder(Layer):\n",
        "    def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,max_len, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, d_model=d_model, max_len=max_len)\n",
        "\n",
        "        self.enc_layers = [\n",
        "                EncoderLayer(d_model=d_model, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate)\n",
        "                for _ in range(num_layers)]\n",
        "        self.dropout = Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.pos_embedding(x)    # Shape `(batch_size, seq_len, d_model)`.\n",
        "        # Add dropout.\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x)\n",
        "\n",
        "        return x    # Shape `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "class DecoderLayer(Layer):\n",
        "    def __init__(self, *, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.causal_self_attention = CausalSelfAttention(\n",
        "                num_heads=num_heads,\n",
        "                key_dim=d_model,\n",
        "                dropout=dropout_rate)\n",
        "\n",
        "        self.cross_attention = CrossAttention(\n",
        "                num_heads=num_heads,\n",
        "                key_dim=d_model,\n",
        "                dropout=dropout_rate)\n",
        "\n",
        "        self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "    def call(self, x, context):\n",
        "        x = self.causal_self_attention(x=x)\n",
        "        x = self.cross_attention(x=x, context=context)\n",
        "\n",
        "        x = self.ffn(x)    # Shape `(batch_size, seq_len, d_model)`.\n",
        "        return x\n",
        "\n",
        "class Decoder(Layer):\n",
        "    def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size, max_len,\n",
        "                             dropout_rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, d_model=d_model, max_len=max_len)\n",
        "        self.dropout = Dropout(dropout_rate)\n",
        "        self.dec_layers = [\n",
        "                DecoderLayer(d_model=d_model, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate)\n",
        "                for _ in range(num_layers)]\n",
        "\n",
        "    def call(self, x, context):\n",
        "        x = self.pos_embedding(x)    # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.dec_layers[i](x, context)\n",
        "\n",
        "        # The shape of x is (batch_size, target_seq_len, d_model).\n",
        "        return x\n",
        "\n",
        "class Transformer(Model):\n",
        "    def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
        "                             input_vocab_size, target_vocab_size,output_vocab_size, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
        "                                                     num_heads=num_heads, dff=dff,\n",
        "                                                     vocab_size=input_vocab_size,\n",
        "                                                     dropout_rate=dropout_rate,\n",
        "                                                     max_len=output_vocab_size)\n",
        "\n",
        "        self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
        "                                                     num_heads=num_heads, dff=dff,\n",
        "                                                     vocab_size=target_vocab_size,\n",
        "                                                     dropout_rate=dropout_rate,\n",
        "                                                     max_len=output_vocab_size)\n",
        "\n",
        "        self.final_layer = Dense(output_vocab_size)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Shape of inputs is (context, x), where context is the input text and x is the target text.\n",
        "        context, x = inputs\n",
        "\n",
        "        context = self.encoder(context)    # (batch_size, context_len, d_model)\n",
        "\n",
        "        x = self.decoder(x, context)    # (batch_size, target_len, d_model)\n",
        "\n",
        "        # Final linear layer output.\n",
        "        logits = self.final_layer(x)    # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "        try:\n",
        "            # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
        "            # b/250038731\n",
        "            del logits._keras_mask\n",
        "        except AttributeError:\n",
        "            pass\n",
        "\n",
        "        # Return the final output and the attention weights.\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom generator\n",
        "\n",
        "The label used in training has the following shape:\n",
        "\n",
        "(`batch_size`, `max_len`, `max_len`)\n",
        "\n",
        "and is the one-hot encoding of the positions of the next correct token from the `Context`.\n",
        "\n",
        "**Example:** If $G_t$ contains the ground truth and $S$ contains the scrambled phrase the label used in training would be:\n",
        "\n",
        "$S = [2,101,102,103,3,0]$\n",
        "\n",
        "$G_t = [2,103,101,102,3,0]$\n",
        "\n",
        "$ Label = \\begin{bmatrix}1,0,0,0,0,0 \\\\\\\n",
        "\t\t  0,0,0,1,0,0 \\\\\\\n",
        "0,1,0,0,0,0 \\\\\\\n",
        "0,0,1,0,0,0 \\\\\\\n",
        "0,0,0,0,1,0 \\\\\\\n",
        "0,0,0,0,0,0 \\end{bmatrix}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_label(shuffled,gt):\n",
        "    batch_size = shuffled.shape[0]\n",
        "    res = np.zeros((batch_size, shuffled.shape[1], shuffled.shape[1]), dtype=np.float32)\n",
        "    for b in range(batch_size):\n",
        "        for i, el in enumerate(gt[b]):\n",
        "            if el == 0:\n",
        "                # If the element is 0, then the rest of the sequence is padding.\n",
        "                mask = np.zeros_like(gt[b], dtype=np.float32)\n",
        "            else:\n",
        "                # Create a mask with 1s up to the element we want to predict.\n",
        "                mask = (shuffled[b]==el).astype(np.float32)\n",
        "                # If there are multiple occurrences of the element, keep only the first one.\n",
        "                idx = np.where(mask == 1)[0][0] + 1\n",
        "                mask[idx:] = 0                \n",
        "\n",
        "            res[b][i] = mask\n",
        "    return res                \n",
        "\n",
        "\"\"\"\n",
        "New data generator that generates the label based on the generated x and y.\n",
        "\"\"\"\n",
        "class DataGeneratorWrapper(DataGenerator):\n",
        "    def __getitem__(self, index):\n",
        "        x, y = super().__getitem__(index)\n",
        "        # Remove the end token from the input.\n",
        "        y_without_end = y.copy()\n",
        "        y_without_end[y == 2] = 0\n",
        "        \n",
        "        y_left_shifted = np.roll(y, -1, axis=1)\n",
        "        label = generate_label(x, y_left_shifted)\n",
        "        return (x, y), label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training\n",
        "\n",
        "### Hyperparameters\n",
        "\n",
        "\n",
        "For the model, the following hyperparameter have been used:\n",
        "\n",
        "- `num_layers` -> **$4$** (number of Encoder and Decoder layers)\n",
        "- `d_model` -> **$172$** (dimension of the token embedding inside the model)\n",
        "- `num_heads` -> **$10$** (number of attention heads in each attention block)\n",
        "- `dff` -> **$512$** (neurons inside a feed forward layer)\n",
        "- `max_length` -> **$32$** (max lenght of each input phrase)\n",
        "- `input_vocab_size` -> **$10\\,000$** (size of the input vocabolary)\n",
        "- `target_vocab_size` -> **$10\\,000$** (size of the target vocabolary)\n",
        "- `output_vocab_size` -> **$28$** (size of the output vocabolary)\n",
        "- `train_size` -> **$220\\,000$** (dimension of the train set)\n",
        "- `validation_size` -> **$3000$** (dimension of the validation set)\n",
        "- `epochs` -> **$64$** (epochs used to train the model)\n",
        "- `learning_rate` -> **$10^{-4}$** (for some learning rate scheduler it varies)\n",
        "- `lr_scheduler` -> **\"constant\"** (learning rate scheduler)\n",
        "- `warmup_steps` -> **Not used** (warmup steps used in some learning rate scheduler)\n",
        "- `weight_decay` -> **$10^{-3}$** (weight decay used in loss function)\n",
        "- `optimizer` -> **\"adamw\"** (optimizer used in training)\n",
        "- `loss` -> **\"categorical_crossentropy\"** (loss used in training)\n",
        "\n",
        "### Training method\n",
        "\n",
        "The laptop used to write this code doesn't have a GPU so to train the model I used another machine and logged all the results and saved the resulting models using [Weights & Biases](http://wandb.ai)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mluca24ever\u001b[0m (\u001b[33mluca24ever_unibo\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.17.1 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>c:\\Users\\Luca\\Desktop\\MagistraleAI\\1st_year\\Deep Learning\\Assignment\\wandb\\run-20240612_091944-eoeci3sg</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/luca24ever_unibo/DLAssignment/runs/eoeci3sg' target=\"_blank\">dark-terrain-69</a></strong> to <a href='https://wandb.ai/luca24ever_unibo/DLAssignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/luca24ever_unibo/DLAssignment' target=\"_blank\">https://wandb.ai/luca24ever_unibo/DLAssignment</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/luca24ever_unibo/DLAssignment/runs/eoeci3sg' target=\"_blank\">https://wandb.ai/luca24ever_unibo/DLAssignment/runs/eoeci3sg</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import wandb\n",
        "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
        "\n",
        "USE_WANDB = True\n",
        "DOWNLOAD_MODEL = True\n",
        "MODEL_TO_DOWNLOAD = 'luca24ever_unibo/DLAssignment/run_hry16xff_model:latest' # Name of the trained model from wandb\n",
        "CONTINUE_TRAINING = False\n",
        "\n",
        "input_vocab_size = tokenizer.vocabulary_size()\n",
        "output_vocab_size = max([len(sen) for sen in original_data]) # Should be 28\n",
        "\n",
        "config = {\n",
        "    \"num_layers\": 4,\n",
        "    \"d_model\": 172,\n",
        "    \"num_heads\": 10,\n",
        "    \"dff\": 512,\n",
        "    \"max_length\": 32,\n",
        "    \"train_size\": 220000,\n",
        "    \"validation_size\": 3000,\n",
        "    \"batch_size\": 32,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"weight_decay\": 1e-3,\n",
        "    \"epochs\": 63,\n",
        "    \"optimizer\": \"adamw\",\n",
        "    \"loss\": \"categorical_crossentropy\",\n",
        "    \"input_vocab_size\": input_vocab_size,\n",
        "    \"target_vocab_size\": input_vocab_size,\n",
        "    \"output_vocab_size\": output_vocab_size,\n",
        "    \"lr_scheduler\": \"constant\",\n",
        "    \"warmup_steps\": 1000,\n",
        "}\n",
        "\n",
        "if USE_WANDB:\n",
        "    run = wandb.init(\n",
        "        # set the wandb project where this run will be logged\n",
        "        project=\"DLAssignment\",\n",
        "        # track hyperparameters and run metadata with the config object\n",
        "        config=config\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Definition\n",
        "\n",
        "The model is composed of $19\\,130\\,524$ trainable params."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "transformer = Transformer(num_layers=config[\"num_layers\"],\n",
        "                          d_model=config[\"d_model\"],\n",
        "                          num_heads=config[\"num_heads\"],\n",
        "                          dff=config[\"dff\"],\n",
        "                          input_vocab_size=config[\"input_vocab_size\"],\n",
        "                          target_vocab_size=config[\"target_vocab_size\"],\n",
        "                          output_vocab_size=config[\"output_vocab_size\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact run_hry16xff_model:latest, 73.20MB. 1 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "Done. 0:0:0.4\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Luca\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:189: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\Luca\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\normalization\\layer_normalization.py:328: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Continue with the previous training\n",
        "if DOWNLOAD_MODEL and USE_WANDB:\n",
        "    MODEL_NAME = \"transformer_model.h5\"\n",
        "\n",
        "    # Download the model from wandb\n",
        "    artifact = run.use_artifact(MODEL_TO_DOWNLOAD, type='model')\n",
        "    artifact_dir = artifact.download()\n",
        "\n",
        "    # Load the downloaded weights into the model\n",
        "    transformer.build(input_shape=[(None, None), (None, None)])\n",
        "    transformer.load_weights(artifact_dir + \"/\" + MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Different Learning Rate scheduler had been tested and the best one was found to be the costant scheduler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BatchLearningRateScheduler(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, schedule):\n",
        "        super(BatchLearningRateScheduler, self).__init__()\n",
        "        self.schedule = schedule\n",
        "\n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
        "        scheduled_lr = self.schedule(batch, lr)\n",
        "        tf.keras.backend.set_value(self.model.optimizer.learning_rate, scheduled_lr)\n",
        "        \n",
        "def lr_schedule_decay(batch, lr):\n",
        "    initial_lr = 0.001\n",
        "    k = 0.0001\n",
        "    return initial_lr * np.exp(-k * batch)\n",
        "\n",
        "def lr_schedule_constant(batch, lr):\n",
        "    return lr\n",
        "\n",
        "def lr_schedule_transformer(batch, lr):\n",
        "    initial_lr = 0.001\n",
        "    warmup_steps = 4000\n",
        "    step_num = batch + 1  # Avoid division by zero\n",
        "    return initial_lr * min(step_num**-0.5, step_num * (warmup_steps**-1.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define all the generators\n",
        "train_generator = DataGeneratorWrapper(original_data[:config[\"train_size\"]-config[\"validation_size\"]], batch_size=config[\"batch_size\"], seed=SEED)\n",
        "validation_generator = DataGeneratorWrapper(original_data[config[\"train_size\"]-config[\"validation_size\"]:config[\"train_size\"]], batch_size=config[\"batch_size\"], shuffle=False, seed=SEED)\n",
        "test_generator = DataGeneratorWrapper(original_data[config[\"train_size\"]:], batch_size=config[\"batch_size\"], shuffle=False, seed=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if CONTINUE_TRAINING:\n",
        "    # Choose the optimizer based on the configuration\n",
        "    if config[\"optimizer\"] == \"adam\":\n",
        "        optimizer = Adam(learning_rate=config[\"learning_rate\"])\n",
        "    elif config[\"optimizer\"] == \"adamw\":\n",
        "        optimizer = AdamW(learning_rate=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
        "    else:\n",
        "        raise ValueError(f'Unknown optimizer: {config[\"optimizer\"]}')\n",
        "\n",
        "    # Choose the loss function based on the configuration\n",
        "    if config[\"loss\"] == \"categorical_crossentropy\":\n",
        "        loss = CategoricalCrossentropy(from_logits=True)\n",
        "    else:\n",
        "        raise ValueError(f'Unknown loss: {config[\"loss\"]}')\n",
        "\n",
        "    # Choose the learning rate scheduler based on the configuration\n",
        "    if config[\"lr_scheduler\"] == \"constant\":\n",
        "        lr_schedule = lr_schedule_constant\n",
        "    elif config[\"lr_scheduler\"] == \"decay\":\n",
        "        lr_schedule = lr_schedule_decay\n",
        "    elif config[\"lr_scheduler\"] == \"transformer\":\n",
        "        lr_schedule = lr_schedule_transformer\n",
        "    else:\n",
        "        raise ValueError(f'Unknown lr_scheduler: {config[\"lr_scheduler\"]}')\n",
        "\n",
        "    lr_scheduler = BatchLearningRateScheduler(lr_schedule)\n",
        "\n",
        "    # Compile the model with the chosen optimizer and loss function\n",
        "    transformer.compile(optimizer=optimizer, loss=loss)\n",
        "\n",
        "    # Train the model with the specified number of epochs and validation data\n",
        "    # and logs the metrics to wandb\n",
        "    if USE_WANDB:\n",
        "        transformer.fit(train_generator, epochs=config[\"epochs\"], validation_data=validation_generator, callbacks=[\n",
        "            WandbMetricsLogger(log_freq=5),\n",
        "            WandbModelCheckpoint(\"transformer_model.h5\", monitor=\"val_loss\", save_best_only=True, save_weights_only=True),\n",
        "            lr_scheduler\n",
        "        ])\n",
        "    else:\n",
        "        transformer.fit(train_generator, epochs=config[\"epochs\"], validation_data=validation_generator, callbacks=[\n",
        "            lr_scheduler\n",
        "        ])\n",
        "\n",
        "    # Save the trained model\n",
        "    transformer.save('transformer.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note**: the output logs of the training are not printed in this notebook because the model was trained on another device. The relevant data are plotted below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder (Encoder)           multiple                  7184768   \n",
            "                                                                 \n",
            " decoder (Decoder)           multiple                  11940912  \n",
            "                                                                 \n",
            " dense_16 (Dense)            multiple                  4844      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19130524 (72.98 MB)\n",
            "Trainable params: 19130524 (72.98 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "transformer.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with open(\"data.json\") as f:\n",
        "\tdata = json.load(f)\n",
        "\n",
        "plt.title(\"Losses during training\")\n",
        "plt.xlabel(\"Batch Step\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(data[\"data_batch_loss\"][\"steps\"], data[\"data_batch_loss\"][\"loss\"], label=\"Batch Train Loss\")\n",
        "\n",
        "plt.plot(data[\"data_val_loss\"][\"steps\"], data[\"data_val_loss\"][\"loss\"], label=\"Epoch Validation Loss\")\n",
        "plt.plot(data[\"data_val_loss\"][\"steps\"][data[\"arg_min_val_loss\"]], data[\"min_val_loss\"], 'ro', label=\"Min Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note**: the step-like trend of the batch train loss is due to a Keras implementation of the logging, because instead of printing the current value of the loss function, it prints the average of the loss from the start of the epoch.\n",
        "\n",
        "**Links**: here I link the plots above directly from Weights & Biases:\n",
        "- [Batch Train Loss](https://api.wandb.ai/links/luca24ever_unibo/hhgp9y16)\n",
        "- [Epoch Val Loss](https://api.wandb.ai/links/luca24ever_unibo/xkcyxcat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation\n",
        "\n",
        "To predict the resulting sentence, only the `<start>` token is fed inside the Decoder and the reordered sentence is fed inside the Encoder. The prediction is made one token at a time that gets appended to the input of the Decoder. The process ends when the model predicts the index of the `<end>` token in the input sentence.  \n",
        "\n",
        "The given score function is used to evaluate the model. The predicted sentence is compared to the ground truth sentence and the strings `<start>` and `<end>` are removed from both.\n",
        "\n",
        "For the inference, a masking mechanism have also been implemented, basically setting to $-\\infty$ all the values of the predictions for the tokens that has already been chosen in order to constraint the output of the network to not choose the same word two times.\n",
        "\n",
        "Nevertheless, post-processing of the output is not allowed in this task, so the variable `USE_MASK` is set to false."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import keras\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "START_TOKEN = 3\n",
        "END_TOKEN = 2\n",
        "PADDING_TOKEN = 0\n",
        "\n",
        "def calculate_avg_score(transformer, test_generator, detokenizer, use_mask=False):\n",
        "    scores = []\n",
        "    \n",
        "    # The ground truth labels are ignored in evaluation\n",
        "    for (input_tokens, truth_tokens), _ in tqdm(test_generator):\n",
        "        batch_size = truth_tokens.shape[0]\n",
        "        truth_sents = [ detokenizer([truth_tokens[b]])[0] for b in range(batch_size) ]\n",
        "        prediction_sentence = [\"\"] * batch_size\n",
        "        prediction_tokens = np.array([[START_TOKEN] + [PADDING_TOKEN] * 27] * batch_size)\n",
        "        \n",
        "        masks = np.zeros((batch_size, 28, 28))\n",
        "\n",
        "        for i in range(27):\n",
        "            out = transformer.predict_on_batch(( np.array(input_tokens), np.array(prediction_tokens) ))\n",
        "\n",
        "            if use_mask:\n",
        "                out = out + masks\n",
        "\n",
        "            for b in range(batch_size):\n",
        "                # If the sentence has already been predicted, skip it\n",
        "                if len(prediction_sentence[b]) != 0: continue\n",
        "                \n",
        "                predicted_token_index = np.argmax(out[b, i, :])\n",
        "                predicted_token = input_tokens[b, predicted_token_index]\n",
        "                \n",
        "                if use_mask:\n",
        "                    # Find the number of occurences of pred_token inside in_tokens[b]\n",
        "                    occurences_input = np.sum(input_tokens[b] == predicted_token)\n",
        "                    occurences_autoregressive = np.sum(prediction_tokens[b] == predicted_token)\n",
        "                    \n",
        "                    # If the predicted token has already been predicted more times than it appears in the input, mask it\n",
        "                    if occurences_autoregressive >= occurences_input:\n",
        "                        masks[b, :, predicted_token_index] = - np.inf\n",
        "                \n",
        "                prediction_tokens[b, i+1] = predicted_token\n",
        "\n",
        "                # If the predicted token is the end token, stop the prediction\n",
        "                if predicted_token == END_TOKEN:\n",
        "                    prediction_sentence[b] = detokenizer([prediction_tokens[b]])[0]\n",
        "            \n",
        "            # If all the sentences have been predicted, stop the prediction\n",
        "            if all([ len(s) > 0 for s in prediction_sentence ]):\n",
        "                break\n",
        "\n",
        "        # Handle sentences without end token\n",
        "        for b in range(len(prediction_sentence)):\n",
        "            if len(prediction_sentence[b]) == 0:\n",
        "                prediction_sentence[b] = detokenizer([prediction_tokens[b]])[0] + \" <end>\"\n",
        "        \n",
        "        for b in range(batch_size):\n",
        "            # Remove <start> and <end> tokens\n",
        "            prediction_sentence[b], truth_sents[b] = prediction_sentence[b][8:-6], truth_sents[b][8:-6] \n",
        "            scores.append( score(truth_sents[b], prediction_sentence[b]) )\n",
        "\n",
        "        # Fix memory leak\n",
        "        gc.collect()\n",
        "        keras.backend.clear_session()\n",
        "        \n",
        "    return len(scores), np.mean(scores), np.std(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 663/663 [34:09<00:00,  3.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Number of test sentences: 21216\n",
            "Average score: 0.6503331317989776\n",
            "Standard deviation of the scores: 0.31162338368881815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "num_scores, avg_score, std_score = calculate_avg_score(transformer, test_generator, detokenizer, use_mask=False)\n",
        "print(f\"\\nNumber of test sentences: {num_scores}\")\n",
        "print(f\"Average score: {avg_score}\")\n",
        "print(f\"Standard deviation of the scores: {std_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Average Score: $0.6503331317989776$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01e2428b016d4c6588e8a399ebbbc367": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d388b76907324629a8dcf22232fbe368",
            "placeholder": "",
            "style": "IPY_MODEL_cc49c1aa52814e8082b2897ef630c5db",
            "value": "1020868/1020868[00:25&lt;00:00,32940.36examples/s]"
          }
        },
        "4be629ac0cc444d7ba724e8e54cb68cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ac9b8152bba473ab9c22d64f69173b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2eb59a45c0e4068a7497bb3a31b188d",
              "IPY_MODEL_ecdfb26b614b490fb8b3c14d606b78b8",
              "IPY_MODEL_01e2428b016d4c6588e8a399ebbbc367"
            ],
            "layout": "IPY_MODEL_4be629ac0cc444d7ba724e8e54cb68cd"
          }
        },
        "ad458b17c52e43a98d9779245b172cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c71e6fdef7b74d9285cc4843b0a4889f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc49c1aa52814e8082b2897ef630c5db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2eb59a45c0e4068a7497bb3a31b188d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7272b54af0b42cd91ae6e1f2a8c66b7",
            "placeholder": "",
            "style": "IPY_MODEL_ad458b17c52e43a98d9779245b172cb9",
            "value": "Filter:100%"
          }
        },
        "d388b76907324629a8dcf22232fbe368": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7272b54af0b42cd91ae6e1f2a8c66b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecdfb26b614b490fb8b3c14d606b78b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c71e6fdef7b74d9285cc4843b0a4889f",
            "max": 1020868,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fead1879bbf1494592e40405ca9ab6fd",
            "value": 1020868
          }
        },
        "fead1879bbf1494592e40405ca9ab6fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
